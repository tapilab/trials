{
 "metadata": {
  "name": "",
  "signature": "sha256:f4ece97020407f92d684c2a9a737b5df435e693e25d64a15e1e7926b0900b453"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Clinical Trial Data\n",
      "\n",
      "\"\"\"We download clinical trials from [ClinicalTrials.gov](http://clinicaltrials.gov)\n",
      "and create a search engine using [Whoosh](https://pythonhosted.org/Whoosh/).\"\"\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 377,
       "text": [
        "'We download clinical trials from [ClinicalTrials.gov](http://clinicaltrials.gov)\\nand create a search engine using [Whoosh](https://pythonhosted.org/Whoosh/).'"
       ]
      }
     ],
     "prompt_number": 377
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# RAWDIR stores the search results from ClinicalTrials.gov, one trial per xml file.\n",
      "RAWDIR='/Users/JingqianLi/Documents/Courses/Trials/search_result'\n",
      "    \n",
      "# The search index will be stored here.\n",
      "INDEXDIR='/Users/JingqianLi/Documents/Courses/Trials/index'\n",
      "!mkdir -p $INDEXDIR"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 378
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob \n",
      "import io\n",
      "import sys, traceback\n",
      "import re\n",
      "    \n",
      "from lxml import etree\n",
      "from whoosh.fields import KEYWORD, DATETIME, ID, Schema, TEXT, NUMERIC\n",
      "from whoosh.index import create_in\n",
      "from whoosh.qparser import QueryParser\n",
      "    \n",
      "class TrialSearcher:\n",
      "    \"\"\" Index a list of trial xml documents to support fielded queries. \"\"\"\n",
      "        \n",
      "    def __init__(self, xml_dir, limit=1000):\n",
      "        \"\"\"\n",
      "        Params:\n",
      "          xml_dir ... path containing a list of xml files, one per trial.\n",
      "          limit ..... maximum number of xml files to index, for testing. \"\"\"\n",
      "        self._create_index(xml_dir, limit)\n",
      "            \n",
      "    def _find_text(self, element, xpathq):\n",
      "        \"\"\" Return the text contents of the results of an xpath query on this element.\n",
      "        Params:\n",
      "          element ... root XML element to search\n",
      "          xpathq .... An XPath query to run.\n",
      "        Returns:\n",
      "          A string containing the text portion of the matching element. If there\n",
      "          multiple matches, they are concatenated. \"\"\"\n",
      "        matches = [x for x in element.xpath(xpathq)]\n",
      "        return u' '.join(unicode(m.text.strip()) for m in matches)\n",
      "        \n",
      "    def _add_doc(self, xmlfile, writer):\n",
      "        \"\"\" Add a single trial XML file as a document in the index.\n",
      "        Params:\n",
      "          xmlfile ... Path to trial XML file.\n",
      "          writer .... The IndexWriter.\"\"\"\n",
      "        tree = etree.parse(io.open(xmlfile, encoding='utf8'))\n",
      "        for study in tree.xpath(\"//clinical_study\"):\n",
      "            \n",
      "            if (self._find_text(study, '//eligibility/maximum_age').lower() != 'n/a'):\n",
      "                max_age = self._find_text(study, '//eligibility/maximum_age').lower()\n",
      "                p = int(re.findall(r'\\d+',max_age)[0])\n",
      "                if (max_age.find('days') != -1):\n",
      "                    maximum_age = p \n",
      "                elif (max_age.find('months') != -1 or max_age.find('month')):\n",
      "                    maximum_age = p * 30 \n",
      "                elif (max_age.find('years') != -1 or max_age.find('year')):\n",
      "                    maximum_age = p * 365\n",
      "            else :\n",
      "                maximum_age = 73000                    # set to 200 years old if maximum age is N/A\n",
      "                \n",
      "            if (self._find_text(study, '//eligibility/minimum_age').lower() != 'n/a'):\n",
      "                min_age = self._find_text(study, '//eligibility/minimum_age').lower()\n",
      "                t = int(re.findall(r'\\d+',min_age)[0])\n",
      "                if (min_age.find('days') != -1):\n",
      "                    minimum_age = t\n",
      "                elif (min_age.find('months') != -1 or min_age.find('month') != -1):\n",
      "                    minimum_age = t * 30\n",
      "                elif (min_age.find('years') != -1 or min_age.find('year') != -1):\n",
      "                    minimum_age = t * 365\n",
      "            else :\n",
      "                minimum_age = 0\n",
      "            \n",
      "            d = {\n",
      "                'completion_date': self._find_text(study, '//completion_date'),\n",
      "                'criteria': self._find_text(study, '//eligibility/criteria/textblock'),\n",
      "                'gender': self._find_text(study, '//eligibility/gender'),\n",
      "                'healthy_volunteers': self._find_text(study, '//eligibility/healthy_volunteers'),\n",
      "                'locations': self._find_text(study, '//location_countries/country'),\n",
      "                'maximum_age': maximum_age,\n",
      "                'minimum_age': minimum_age,\n",
      "                'nct_id': self._find_text(study, '//id_info/nct_id'),\n",
      "                'title': self._find_text(study, '//brief_title'),\n",
      "                'source': self._find_text(study, '//source'),\n",
      "                'start_date': self._find_text(study, '//start_date'),\n",
      "                }\n",
      "            # FIXME: consider Boolean, Numeric field types.\n",
      "            writer.add_document(**d)\n",
      "            \n",
      "    def _create_index(self, xml_dir, limit):\n",
      "        \"\"\" Create an index containing the contents of the trial xml directory.\n",
      "        Params:\n",
      "          xml_dir ... path to list of trial xml files.\n",
      "          limit ..... Only read this many xml files, for testing.\"\"\"\n",
      "        schema = Schema(\n",
      "                        completion_date=TEXT,\n",
      "                        criteria=TEXT(stored=True),\n",
      "                        gender=TEXT,\n",
      "                        healthy_volunteers=TEXT,\n",
      "                        locations=TEXT,\n",
      "                        maximum_age=NUMERIC(stored=True),      #change the ID type to numeric, invert the unit to DAYS\n",
      "                        minimum_age=NUMERIC(stored=True),     \n",
      "                        nct_id=ID(stored=True),\n",
      "                        title=TEXT(stored=True),\n",
      "                        source=TEXT,\n",
      "                        start_date=TEXT\n",
      "                        )\n",
      "    \n",
      "        self.index = create_in(INDEXDIR, schema)\n",
      "        writer = self.index.writer(limitmb=1000)  # CHANGE THE LIMIT\n",
      "        count = 0\n",
      "        for xmlfile in glob.glob(xml_dir + '/*.xml'):    # ??\n",
      "            try:\n",
      "                self._add_doc(xmlfile, writer)\n",
      "            except:\n",
      "                print 'cannot parse file %s' % xmlfile\n",
      "            count += 1\n",
      "            if count % 100 == 0:\n",
      "                print 'indexed %d documents' % count\n",
      "            if count == limit:\n",
      "                break\n",
      "        writer.commit()\n",
      "    \n",
      "    def search(self, query_str, limit=100):\n",
      "        \"\"\" Exectue a query on this index.\n",
      "        Params:\n",
      "          query_str: A possibly fielded query string. Searches the 'criteria' field by default.\n",
      "          limit: Maximum number of results to return.\n",
      "        Return:\n",
      "          A rank-ordered list of document ids.\"\"\"\n",
      "        parser = QueryParser('criteria', schema=self.index.schema)\n",
      "        with self.index.searcher() as searcher:\n",
      "            query = parser.parse(query_str)\n",
      "            print 'query=', query\n",
      "            results = searcher.search(query, limit=limit)\n",
      "            return [r.docnum for r in results]\n",
      "        \n",
      "    def print_results(self, results):\n",
      "        \"\"\" Print to stdout a list of search results.\n",
      "        Params:\n",
      "          results: A rank-ordered list of document ids.\"\"\"\n",
      "        with self.index.searcher() as searcher:    #returns an iterator of docnums matching this query\n",
      "            for r in results:\n",
      "                doc = searcher.stored_fields(r)\n",
      "                print '\\t'.join([doc['nct_id'], doc['title']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 379
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "searcher = TrialSearcher(RAWDIR, limit=1310)\n",
      "results = searcher.search(u'gender:both AND criteria:cancer AND criteria:thyroid AND healthy_volunteers:Accepts') #Caution! no spaces after ':'\n",
      "print 'results='\n",
      "searcher.print_results(results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "indexed 100 documents\n",
        "indexed 200 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "indexed 300 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "indexed 400 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "indexed 500 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "indexed 600 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "indexed 700 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "indexed 800 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "indexed 900 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "indexed 1000 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "indexed 1100 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "indexed 1200 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "indexed 1300 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "query="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (gender:both AND criteria:cancer AND criteria:thyroid AND healthy_volunteers:accepts)\n",
        "results=\n",
        "NCT00999557\tBimatoprost Ophthalmic Solution in Increasing Eyebrow and Eyelash Growth in Patients Who Have Undergone Chemotherapy for Breast Cancer and in Healthy Participants\n"
       ]
      }
     ],
     "prompt_number": 380
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 380
    }
   ],
   "metadata": {}
  }
 ]
}